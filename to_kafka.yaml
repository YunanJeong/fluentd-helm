forwarder:
  enabled: false

## Aggregator parameters
##
aggregator:
  enabled: true
  replicaCount: 1


  ## @param aggregator.extraGems List of extra gems to be installed. Can be used to install additional fluentd plugins.
  ##
  extraGems: []
    # - name: fluent-plugin-beats 
    #   version: 2.1.2
  ## @param aggregator.configFile Name of the config file that will be used by Fluentd at launch under the `/opt/bitnami/fluentd/conf` directory
  ##
  configFile: fluentd.conf
  ## @param aggregator.configMap Name of the config map that contains the Fluentd configuration files
  ##
  configMap: ""
  ## @param aggregator.configMapFiles [object] Files to be added to be config map. Ignored if `aggregator.configMap` is set
  ##
  configMapFiles:
    # 디폴트 conf파일에 테스트 및 모니터링 등 기본기능을 위한 설정이 포함됨
    # 디폴트 conf내용 삭제시, value파일에서 관련기능 프로퍼티를 찾아 disabled해줘야 에러방지됨
    
    # :9880  # kubelet이 헬스체크(Probe)하려고 httpGet할 수 있도록 제공하는 포트
             # POST로 json받으면 stdout(pod로그)로 띄워주므로 테스트용도로 겸사겸사 사용가능
    # :24224 # forwarder로부터 데이터를 받기위한 포트
    # :24231 # 외부 Prometheus가 fluentd의 메트릭을 Pull Request할 수 있도록 제공하는 포트
    fluentd.conf: |
      # Ignore fluentd own events
      <match fluent.**>
        @type null
      </match>

      @include kafka-produce.conf

      # @include kafka-consume.conf
      
      @include kafka-consume-group.conf

      
      @include fluentd-inputs.conf
      @include fluentd-output.conf
      {{- if .Values.metrics.enabled }}
      @include metrics.conf
      {{- end }}

    kafka-produce.conf: |
      <source>
        # in_http 플러그인: source섹션에서 tag지정 불가
        # URL subpath가 source tag로 취급됨
        # e.g) <fluentd_ip>:8888/kafka.produce
        @type http   
        bind 0.0.0.0
        port 8888
      </source>

      <match kafka.produce>
        @type kafka2  # Produce plugin   
        brokers my-kfk-kafka.default.svc.cluster.local:9092  # 콤마로 여러 주소 지정 가능(failure시 사용됨)
        default_topic fluentd-test                         # 멀티토픽 불가, tag routing으로 개별처리 필요

        # json만 받는다
        <format>
          @type json
        </format>
        
        # file 버퍼: 안정성, 확장성 중시 => 누락 원천차단, 근데 느림 (라이브시, pv 활성화 필요)
        # memory 버퍼: 속도 중시 => 애초에 버퍼를 많이 안쓰고 빠르게 처리되는게 바람직, 근데 누락위험
        <buffer>
          @type file
          path /opt/bitnami/fluentd/logs/buffers/kafka.produce.buffer   # /opt/bitnami/fluentd/logs/buffers까지는 차트에서 강제하는 PV경로
          flush_interval 1s
          flush_thread_count 5
          chunk_limit_size 512kb 
          retry_max_interval 30s
        </buffer>
      </match>

    kafka-consume-group.conf: |
      <source>
        @type kafka_group  # Consume plugin
        brokers my-kfk-kafka.default.svc.cluster.local:9092
        consumer_group fltd-consumer-group
        topics /fluentd-.*/       # 멀티토픽 콤마 구분 지원, regex 가능!! # topic명이 tag로 사용됨
        format json               # text|json|ltsv|msgpack   # default: json

        # kafka record의 key도 활용하기
        # record key 텍스트를 fluentd 이벤트의 지정한 필드값("record_key")으로 저장. 
        kafka_message_key record_key   # Optional. format옵션과 함께 사용. 

        # false면 최신부터 읽음. 첫 실행시에만 중요.
        # 재기동할 땐 consumer-group의 offset을 따르기 때문에 이 설정값과 상관없이 안읽은부분부터 읽음
        start_from_beginning true # default true
      </source>
      <match kafka.fluentd-test>
        @type stdout

        # consumer-group 사용시 kafka측에서 offset 관리하므로 file buffer 없어도됨
        <buffer>
          @type memory
          flush_mode interval
          flush_interval 2s
          flush_thread_count 4
          chunk_limit_size 2MB #as small as possible
          total_limit_size 4GB
          retry_max_interval 30 
          retry_forever true
        </buffer>

      </match>

    kafka-consume.conf: |
      <source>
        @type kafka  # Consume plugin(Non-consumer-group)  # 비권장
        
        # consumer-group을 생성하지 않는 단일 consumer
        # 단일 partition만 접근가능. default 0번    
        # broker에 __consumer_offset이 기록되지 않음, 중복 및 누락 위험성
          # => file buffer 필수
        # 실행시 대상 partition에서 읽기 시작할 offset을 수동지정가능, default -1(현재 최신 Record부터 가져옴)
        
        # tag는 토픽명을 따름
        brokers my-kfk-kafka.default.svc.cluster.local:9092
        format json          # text|json|ltsv|msgpack   # default: json
        topics fluentd-test  # 콤마 구분 멀티토픽지원, regex 불가
        
        # topic 별 처리하기
        # <topic>
        #   topic     <listening topic>
        #   partition <listening partition: default=0>
        #   offset    <listening start offset: default=-1>
        # </topic>
        # <topic>
        #   topic     <listening topic>
        #   partition <listening partition: default=0>
        #   offset    <listening start offset: default=-1>
        # </topic>

      </source>
      <match kafka.fluentd-test>
        @type stdout

        # Kafka 측에서 offset관리가 되지 않으므로 file buffer 필수
        <buffer>
          @type file
          path /opt/bitnami/fluentd/logs/buffers/kafka.consume.buffer   # /opt/bitnami/fluentd/logs/buffers까지는 차트에서 강제하는 PV경로
          flush_interval 1s
          flush_thread_count 5
          chunk_limit_size 512kb 
          retry_max_interval 30s
        </buffer>

      </match>

    fluentd-inputs.conf: |
      # TCP input to receive logs from
      {{- if .Values.aggregator.port }}
      <source>
        @type forward
        bind 0.0.0.0
        port {{ .Values.aggregator.port }}
        {{- if .Values.tls.enabled }}
        <transport tls>
          ca_path /opt/bitnami/fluentd/certs/in_forward/ca.crt
          cert_path /opt/bitnami/fluentd/certs/in_forward/tls.crt
          private_key_path /opt/bitnami/fluentd/certs/in_forward/tls.key
          client_cert_auth true
        </transport>
        {{- end }}
      </source>
      {{- end }}

      # HTTP input for the liveness and readiness probes
      <source>
        @type http
        bind 0.0.0.0
        port 9880
      </source>
    fluentd-output.conf: |
      # Throw the healthcheck to the standard output
      <match fluentd.healthcheck>
        @type stdout
      </match>

      # Send the logs to the standard output
      <match **>
        @type stdout
      </match>
    metrics.conf: |
      # Prometheus Exporter Plugin
      # input plugin that exports metrics
      <source>
        @type prometheus
        port {{ .Values.metrics.service.port }}
      </source>

      # input plugin that collects metrics from MonitorAgent
      <source>
        @type prometheus_monitor
        <labels>
          host ${hostname}
        </labels>
      </source>

      # input plugin that collects metrics for output plugin
      <source>
        @type prometheus_output_monitor
        <labels>
          host ${hostname}
        </labels>
      </source>
  
  ## @param aggregator.port Port the Aggregator container will listen for logs. Leave it blank to ignore.
  ## You can specify other ports in the aggregator.containerPorts parameter
  ##
  port: 24224
  ## @param aggregator.extraArgs Extra arguments for the Fluentd command line
  ## ref: https://docs.fluentd.org/deployment/command-line-option
  ##
  extraArgs: ""
  ## @param aggregator.extraEnvVars Extra environment variables to pass to the container
  ## extraEnvVars:
  ##   - name: MY_ENV_VAR
  ##     value: my_value
  ##
  extraEnvVars: []
  ## @param aggregator.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Fluentd Aggregator nodes
  ##
  extraEnvVarsCM: ""
  ## @param aggregator.extraEnvVarsSecret Name of existing Secret containing extra env vars for Fluentd Aggregator nodes
  ##
  extraEnvVarsSecret: ""
  ## @param aggregator.containerPorts [array] Ports the aggregator containers will listen on
  ##
  containerPorts:
    # - name: my-port
    #   containerPort: 24222
    #   protocol: TCP
    - name: http
      containerPort: 9880
      protocol: TCP
    - name: test
      containerPort: 8888
      protocol: TCP
  ## Service parameters
  ##
  service:
    ## @param aggregator.service.type Kubernetes service type (`ClusterIP`, `NodePort`, or `LoadBalancer`) for the aggregators
    ##
    type: LoadBalancer
    ## @param aggregator.service.ports [object] Array containing the aggregator service ports
    ##
    ports:
      http:
        port: 9880
        targetPort: http
        protocol: TCP
      tcp:
        port: 24224
        targetPort: tcp
        protocol: TCP
      test:
        port: 8888
        targetPort: test
        protocol: TCP

    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    clusterIP: ""
    annotations: {}
    externalTrafficPolicy: Cluster
    sessionAffinity: None
    sessionAffinityConfig: {}
    annotationsHeadless: {}


  ingress:
    enabled: false
  
  startupProbe:
    enabled: false

  livenessProbe:
    enabled: true
    httpGet:
      path: /fluentd.healthcheck?json=%7B%22ping%22%3A+%22pong%22%7D
      port: http
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  readinessProbe:
    enabled: false

  updateStrategy:
    type: RollingUpdate

  resources: {}

  nodeSelector: {}
  
  autoscaling:
    enabled: false

  ## Persist data to a persistent volume
  ##
  persistence:
    enabled: false
    storageClass: ""
    accessModes:
      - ReadWriteOnce
    size: 10Gi
    ## @param aggregator.persistence.selector Selector to match an existing Persistent Volume (this value is evaluated as a template)
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    selector: {}
    ## @param aggregator.persistence.annotations Persistent Volume Claim annotations
    ##
    annotations: {}


  sidecars: []

  initContainers: # []
    - name: install-offline-plugins
      image: '{{ include "fluentd.aggregator.image" . }}'  # 동일 이미지 tpl
      imagePullPolicy: IfNotPresent
      # 명령어 Permission Denied 방지
      securityContext:
        allowPrivilegeEscalation: false
        runAsUser: 0
      command: [sh, -c]
      args:
        - |-
          # install gems in Init Container
          fluent-gem install /plugins/*.gem

          # copy installed gems to shared dir
          cp -r /opt/bitnami/fluentd/extensions/* /extensions/
          cp -r /opt/bitnami/fluentd/gems/* /gems/
          cp -r /opt/bitnami/fluentd/specifications/* /specifications

      # init Container에 Volume 추가(마운트)
      volumeMounts:
        # 로컬 설치파일을 init container에 등록
        - name: local-gems
          mountPath: /plugins         # init container 내부 경로
        # App Container, Init Container 간 공유 볼륨
        - name: shared-dir  
          mountPath: /extentions      # init container 내부 경로
          subPath: extentions         # 볼륨 내 서브경로 매칭
        - name: shared-dir     
          mountPath: /gems            # init container 내부 경로
          subPath: gems               # 볼륨 내 서브경로 매칭
        - name: shared-dir
          mountPath: /specifications  # init container 내부 경로
          subPath: specifications     # 볼륨 내 서브경로 매칭

  # 새 볼륨을 정의할 때 사용
  extraVolumes: # []
    # 로컬호스트(Node)와 Init Container 간 공유 볼륨
    - name: local-gems
      hostPath:     
        type: Directory
        path: /etc/plugins  # 로컬호스트 경로
    # App Container, Init Container 간 공유 볼륨
    - name: shared-dir
      emptyDir: {}  
      
  # 정의된 볼륨을 컨테이너 내부 경로에 마운트할 때 사용
  extraVolumeMounts: # []
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/extensions/      # App. Container 내부 경로
      subPath: extensions
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/gems/            # App. Container 내부 경로
      subPath: gems
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/specifications/  # App. Container 내부 경로
      subPath: specifications

   
  extraVolumeClaimTemplates: []
  initScripts: {}
  initScriptsCM: ""
  initScriptsSecret: ""

## Prometheus Exporter / Metrics
##
metrics:
  enabled: false

tls:
  enabled: false
