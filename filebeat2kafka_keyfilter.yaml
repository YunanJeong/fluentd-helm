forwarder:
  enabled: false

## Aggregator parameters
##
aggregator:
  enabled: true
  replicaCount: 3


  ## @param aggregator.extraGems List of extra gems to be installed. Can be used to install additional fluentd plugins.
  ##
  extraGems: []
    # - name: fluent-plugin-beats 
    #   version: 2.1.2
  ## @param aggregator.configFile Name of the config file that will be used by Fluentd at launch under the `/opt/bitnami/fluentd/conf` directory
  ##
  configFile: fluentd.conf
  ## @param aggregator.configMap Name of the config map that contains the Fluentd configuration files
  ##
  configMap: ""
  ## @param aggregator.configMapFiles [object] Files to be added to be config map. Ignored if `aggregator.configMap` is set
  ##
  configMapFiles:
    # 디폴트 conf파일에 테스트 및 모니터링 등 기본기능을 위한 설정이 포함됨
    # 디폴트 conf내용 삭제시, value파일에서 관련기능 프로퍼티를 찾아 disabled해줘야 에러방지됨
    
    # :9880  # kubelet이 헬스체크(Probe)하려고 httpGet할 수 있도록 제공하는 포트
             # POST로 json받으면 stdout(pod로그)로 띄워주므로 테스트용도로 겸사겸사 사용가능
             # fluentd pod 관리에 사용되므로, 실제 메시지는 별도 http port를 활용하자
    # :24224 # fluentbit or fluentd로부터 데이터를 받기위한 포트. tag가 유지됨.
    # :24231 # 외부 Prometheus가 fluentd의 메트릭을 Pull Request할 수 있도록 제공하는 포트
    fluentd.conf: |
      #######################################################
      # Filebeat 데이터를 받을 때는 worker 사용보다는, fluentd replica를 늘려서 멀티프로세싱을 구현하는 것이 좋다.

      # fluent-plugin-beats에서 worker적용시 worker 수 만큼 포트번호가 1씩 늘어나 관리가 번거롭다.
      # 결국 filebeat 데이터 수신엔 worker 1개만 사용할 수 밖에 없는데, 이러면 후속처리하는 filter, match에 멀티프로세싱이 적용되어있어도 worker 1개에서만 처리된다. 
    
      # fluentd 내 이벤트는 동일 worker에서만 전달되기 때문이다. worker 간 전달은 불가.
      # output플러그인(out-kafka)이 멀티프로세싱을 지원하더라도, input플러그인(in-filebeat)에서 멀티프로세싱을 미적용시 output도 단일 worker에서만 처리되고 다른 worker는 놀게 된다.
      
      # 따라서 데이터 순서가 중요하지 않다면 fluentd replica를 늘려서 구현하는 것이 좋다.
      # LoadBalancer 서비스가 있기 때문에 단일수신포트를 외부에 제공할 수 있어서 사용상에도 더 간편하다.
      #######################################################
      @include test-in-http-bytes.conf


      @include in-filebeat.conf


      @include out-kafka.conf


      #######################################################
      # 기본 셋업에 쓰이는 Default 설정들
      #######################################################
      # Ignore fluentd own events
      <label @FLUENT_LOG>
        <match fluent.**>
          @type null
        </match>
      </label>
      @include default-fluentd-inputs.conf
      @include default-fluentd-output.conf   # <match **>가 있으므로 항상 마지막에 기술해야 함
      {{- if .Values.metrics.enabled }}
      <worker 0>
        @include default-metrics.conf
      </worker>
      {{- end }}

    test-in-http-bytes.conf: |
      <source>
        # in_http는 worker 개수에 자동맞춤
        @type http   
        bind 0.0.0.0
        port 8888
        <parse>
          @type none       
          message_key message
        </parse>
      </source>

    in-filebeat.conf: |
      # fluent-plugin-beats는 "단일포트"에 대한 멀티프로세싱 미지원
      # worker 사용시 포트가 1씩 늘어나는 방식이라, 운영&관리가 번거롭다.
      <source>
        @type beats
        tag live.beat   # metadata_as_tag
        port 5044       # bind 0.0.0.0 (default)
      </source>
      <source>
        @type beats
        tag alpha.beat
        port 5045
      </source>

    out-kafka.conf: |
      <filter *.beat>
        @type record_modifier

        # 태그 기반 토픽 라우팅을 위한 필드 추가
        <record>
          topickey "fltd.${tag_parts[0]}"   # fltd.live, fltd.alpha
          pod ${ENV['POD_NAME']}
        </record>

        # 화이트리스트 지정 필드만 남기기  # message가 비즈니스데이터 # fields, log는 트러블 슈팅을 용도
        whitelist_keys topickey,pod,fields,log,message
      </filter>
      
      <match *.beat>
        @type kafka2  # Produce plugin   
        brokers my-kfk-kafka.default.svc.cluster.local:9092  

        topic_key topickey          # 데이터 내 특정 키값으로 토픽명 지정 # 멀티토픽 전송 방법
        # default_topic my-topic    # topic_key 필드가 없을 경우 기본 토픽명 # 미지정시 태그명 # 멀티토픽 불가
        # topic my-topic            # 전송할 토픽명  # 멀티토픽 불가

        # ruby hash의 최종출력을 json으로 포맷팅  # json 불만족시 누락되지만, filebeat 랩핑 메시지라 json만족 # message값의 json유효성은 Kafka Streams에서 검사  
        <format>
          @type json
        </format>

        # 일반적인 buffer 옆에는 chunk key 자리인데, 동일한 key끼리 하나의 버퍼 청크(파일)로 묶는다.  다른 key 끼리 하나의 청크가 되지 않도록 한다.
        # tag로 지정 or 메시지 내 특정 필드 등 선택가능  # 미지정시 모든 유형 메시지가 단일 청크에 뒤섞일 수 있음
        # Kafka buffer 한정으로, topic_key와 동일한 필드 설정시, value가 없으면 default_topic을 사용하는 로직이 있음.
        # chunk key는 필수는 아닌데 알파, 라이브 환경정도는 나누는 게 좋을 듯 싶다.
        <buffer topickey>
          @type file

          # 멀티코어 사용시 파일버퍼명에 식별자 붙이기
          # /opt/bitnami/fluentd/logs/buffers까지는 차트에서 강제하는 PV경로  # worker_id 안붙여도 내부에서 자동 경로 구분하긴하는데, 버전/환경마다 달라서 붙이는게 좋음
          path "/opt/bitnami/fluentd/logs/buffers/to_kafka/work_#{worker_id}"   
          flush_interval 1s
          flush_thread_count 5
          chunk_limit_size 512kb  # as small as possible
          total_limit_size 64GB   # Default: 512MB (memory) / 64GB (file)
          retry_max_interval 30s
        </buffer>
      </match>


    default-fluentd-inputs.conf: |
      # TCP input to receive logs from
      {{- if .Values.aggregator.port }}
      <source>
        @type forward
        bind 0.0.0.0
        port {{ .Values.aggregator.port }}
        {{- if .Values.tls.enabled }}
        <transport tls>
          ca_path /opt/bitnami/fluentd/certs/in_forward/ca.crt
          cert_path /opt/bitnami/fluentd/certs/in_forward/tls.crt
          private_key_path /opt/bitnami/fluentd/certs/in_forward/tls.key
          client_cert_auth true
        </transport>
        {{- end }}
      </source>
      {{- end }}

      # HTTP input for the liveness and readiness probes
      <source>
        @type http
        bind 0.0.0.0
        port 9880
      </source>
    default-fluentd-output.conf: |
      # Throw the healthcheck to the standard output
      <match fluentd.healthcheck>
        @type stdout
      </match>

      # Send the logs to the standard output
      <match **>
        @type stdout
      </match>
    default-metrics.conf: |
      # Prometheus Exporter Plugin
      # input plugin that exports metrics
      <source>
        @type prometheus
        port {{ .Values.metrics.service.port }}
      </source>

      # input plugin that collects metrics from MonitorAgent
      <source>
        @type prometheus_monitor
        <labels>
          host ${hostname}
        </labels>
      </source>

      # input plugin that collects metrics for output plugin
      <source>
        @type prometheus_output_monitor
        <labels>
          host ${hostname}
        </labels>
      </source>
  
  ## @param aggregator.port Port the Aggregator container will listen for logs. Leave it blank to ignore.
  ## You can specify other ports in the aggregator.containerPorts parameter
  ##
  port: 24224
  ## @param aggregator.extraArgs Extra arguments for the Fluentd command line
  ## ref: https://docs.fluentd.org/deployment/command-line-option
  ##
  extraArgs: ""
  ## @param aggregator.extraEnvVars Extra environment variables to pass to the container
  ## extraEnvVars:
  ##   - name: MY_ENV_VAR
  ##     value: my_value
  ##
  extraEnvVars: # []
    - name: TZ
      value: Asia/Seoul
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
  ## @param aggregator.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Fluentd Aggregator nodes
  ##
  extraEnvVarsCM: ""
  ## @param aggregator.extraEnvVarsSecret Name of existing Secret containing extra env vars for Fluentd Aggregator nodes
  ##
  extraEnvVarsSecret: ""
  ## @param aggregator.containerPorts [array] Ports the aggregator containers will listen on
  ##
  containerPorts:
    - name: livebeat
      containerPort: 5044
      protocol: TCP
    - name: alphabeat
      containerPort: 5045
      protocol: TCP
    - name: http
      containerPort: 9880
      protocol: TCP
    - name: test
      containerPort: 8888
      protocol: TCP
  ## Service parameters
  ##
  service:
    ## @param aggregator.service.type Kubernetes service type (`ClusterIP`, `NodePort`, or `LoadBalancer`) for the aggregators
    ##
    type: LoadBalancer
    ## @param aggregator.service.ports [object] Array containing the aggregator service ports
    ##
    ports:
      livebeat:
        port: 5044
        targetPort: livebeat
        protocol: TCP
      alphabeat:
        port: 5045
        targetPort: alphabeat
        protocol: TCP
      http:
        port: 9880
        targetPort: http
        protocol: TCP
      tcp:
        port: 24224
        targetPort: tcp
        protocol: TCP
      test:
        port: 8888
        targetPort: test
        protocol: TCP

    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    clusterIP: ""
    annotations: {}
    externalTrafficPolicy: Cluster
    sessionAffinity: None
    sessionAffinityConfig: {}
    annotationsHeadless: {}


  ingress:
    enabled: false
  
  startupProbe:
    enabled: false

  livenessProbe:
    enabled: true
    httpGet:
      path: /fluentd.healthcheck?json=%7B%22ping%22%3A+%22pong%22%7D
      port: http
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  readinessProbe:
    enabled: false

  updateStrategy:
    type: RollingUpdate

  resources: {}

  nodeSelector: {}
  
  autoscaling:
    enabled: false

  ## Persist data to a persistent volume
  ##
  persistence:
    enabled: false
    storageClass: ""
    accessModes:
      - ReadWriteOnce
    size: 70Gi # fluentd buffer default size 64G
    ## @param aggregator.persistence.selector Selector to match an existing Persistent Volume (this value is evaluated as a template)
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    selector: {}
    ## @param aggregator.persistence.annotations Persistent Volume Claim annotations
    ##
    annotations: {}


  sidecars: []

  initContainers: # []
    - name: install-offline-plugins
      image: '{{ include "fluentd.aggregator.image" . }}'  # 동일 이미지 tpl
      imagePullPolicy: IfNotPresent
      # 명령어 Permission Denied 방지
      securityContext:
        allowPrivilegeEscalation: false
        runAsUser: 0
      command: [sh, -c]
      args:
        - |-
          # install gems in Init Container
          fluent-gem install /plugins/*.gem

          # copy installed gems to shared dir
          cp -r /opt/bitnami/fluentd/extensions/* /extensions/
          cp -r /opt/bitnami/fluentd/gems/* /gems/
          cp -r /opt/bitnami/fluentd/specifications/* /specifications

      # init Container에 Volume 추가(마운트)
      volumeMounts:
        # 로컬 설치파일을 init container에 등록
        - name: local-gems
          mountPath: /plugins         # init container 내부 경로
        # App Container, Init Container 간 공유 볼륨
        - name: shared-dir  
          mountPath: /extentions      # init container 내부 경로
          subPath: extentions         # 볼륨 내 서브경로 매칭
        - name: shared-dir     
          mountPath: /gems            # init container 내부 경로
          subPath: gems               # 볼륨 내 서브경로 매칭
        - name: shared-dir
          mountPath: /specifications  # init container 내부 경로
          subPath: specifications     # 볼륨 내 서브경로 매칭

  # 새 볼륨을 정의할 때 사용
  extraVolumes: # []
    # 로컬호스트(Node)와 Init Container 간 공유 볼륨
    - name: local-gems
      hostPath:     
        type: Directory
        path: /etc/plugins  # 로컬호스트 경로
    # App Container, Init Container 간 공유 볼륨
    - name: shared-dir
      emptyDir: {}  
      
  # 정의된 볼륨을 컨테이너 내부 경로에 마운트할 때 사용
  extraVolumeMounts: # []
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/extensions/      # App. Container 내부 경로
      subPath: extensions
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/gems/            # App. Container 내부 경로
      subPath: gems
    - name: shared-dir
      mountPath: /opt/bitnami/fluentd/specifications/  # App. Container 내부 경로
      subPath: specifications

   
  extraVolumeClaimTemplates: []
  initScripts: {}
  initScriptsCM: ""
  initScriptsSecret: ""

## Prometheus Exporter / Metrics
##
metrics:
  enabled: false

tls:
  enabled: false
  autoGenerated: false
